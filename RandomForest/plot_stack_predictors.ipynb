{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Combine predictors using stacking\n",
    "\n",
    "\n",
    "Stacking refers to a method to blend estimators. In this strategy, some\n",
    "estimators are individually fitted on some training data while a final\n",
    "estimator is trained using the stacked predictions of these base estimators.\n",
    "\n",
    "In this example, we illustrate the use case in which different regressors are\n",
    "stacked together and a final linear penalized regressor is used to output the\n",
    "prediction. We compare the performance of each individual regressor with the\n",
    "stacking strategy. Stacking slightly improves the overall performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Authors: Guillaume Lemaitre <g.lemaitre58@gmail.com>\n",
    "# License: BSD 3 clause"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``plot_regression_results`` is used to plot the predicted and\n",
    "true targets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_regression_results(ax, y_true, y_pred, title, scores, elapsed_time):\n",
    "    \"\"\"Scatter plot of the predicted vs true targets.\"\"\"\n",
    "    ax.plot([y_true.min(), y_true.max()],\n",
    "            [y_true.min(), y_true.max()],\n",
    "            '--r', linewidth=2)\n",
    "    ax.scatter(y_true, y_pred, alpha=0.2)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.get_xaxis().tick_bottom()\n",
    "    ax.get_yaxis().tick_left()\n",
    "    ax.spines['left'].set_position(('outward', 10))\n",
    "    ax.spines['bottom'].set_position(('outward', 10))\n",
    "    ax.set_xlim([y_true.min(), y_true.max()])\n",
    "    ax.set_ylim([y_true.min(), y_true.max()])\n",
    "    ax.set_xlabel('Measured')\n",
    "    ax.set_ylabel('Predicted')\n",
    "    extra = plt.Rectangle((0, 0), 0, 0, fc=\"w\", fill=False,\n",
    "                          edgecolor='none', linewidth=0)\n",
    "    ax.legend([extra], [scores], loc='upper left')\n",
    "    title = title + '\\n Evaluation in {:.2f} seconds'.format(elapsed_time)\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stack of predictors on a single data set\n",
    "##############################################################################\n",
    " It is sometimes tedious to find the model which will best perform on a given\n",
    " dataset. Stacking provide an alternative by combining the outputs of several\n",
    " learners, without the need to choose a model specifically. The performance of\n",
    " stacking is usually close to the best model and sometimes it can outperform\n",
    " the prediction performance of each individual model.\n",
    "\n",
    " Here, we combine 3 learners (linear and non-linear) and use a ridge regressor\n",
    " to combine their outputs together.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'StackingRegressor' from 'sklearn.ensemble' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a41db4b252dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackingRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menable_hist_gradient_boosting\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHistGradientBoostingRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLassoCV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'StackingRegressor' from 'sklearn.ensemble' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  # noqa\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "estimators = [\n",
    "    ('Random Forest', RandomForestRegressor(random_state=42)),\n",
    "    ('Lasso', LassoCV()),\n",
    "    ('Gradient Boosting', HistGradientBoostingRegressor(random_state=0))\n",
    "]\n",
    "stacking_regressor = StackingRegressor(\n",
    "    estimators=estimators, final_estimator=RidgeCV()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the Boston data set (prediction of house prices). We check the\n",
    "performance of each individual predictor as well as the stack of the\n",
    "regressors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict\n",
    "\n",
    "X, y = load_boston(return_X_y=True)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(9, 7))\n",
    "axs = np.ravel(axs)\n",
    "\n",
    "for ax, (name, est) in zip(axs, estimators + [('Stacking Regressor',\n",
    "                                               stacking_regressor)]):\n",
    "    start_time = time.time()\n",
    "    score = cross_validate(est, X, y,\n",
    "                           scoring=['r2', 'neg_mean_absolute_error'],\n",
    "                           n_jobs=-1, verbose=0)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    y_pred = cross_val_predict(est, X, y, n_jobs=-1, verbose=0)\n",
    "    plot_regression_results(\n",
    "        ax, y, y_pred,\n",
    "        name,\n",
    "        (r'$R^2={:.2f} \\pm {:.2f}$' + '\\n' + r'$MAE={:.2f} \\pm {:.2f}$')\n",
    "        .format(np.mean(score['test_r2']),\n",
    "                np.std(score['test_r2']),\n",
    "                -np.mean(score['test_neg_mean_absolute_error']),\n",
    "                np.std(score['test_neg_mean_absolute_error'])),\n",
    "        elapsed_time)\n",
    "\n",
    "plt.suptitle('Single predictors versus stacked predictors')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stacked regressor will combine the strengths of the different regressors.\n",
    "However, we also see that training the stacked regressor is much more\n",
    "computationally expensive.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
